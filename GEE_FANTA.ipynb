{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports, global consts, inits\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "#Note: If you haven't set a default project for earthengine to use via CLI, you'll need to provide ee.Initialize() with project name\n",
    "#see https://developers.google.com/earth-engine/guides/auth\n",
    "ee.Initialize()\n",
    "map = geemap.Map()\n",
    "\n",
    "sudanStateBorders = ee.FeatureCollection(\"projects/seamproj01/assets/SudanStateBorders\")    #Shapefiles for Sudan administration borders, via OCHA HDX. This dataset is used for \n",
    "                                                                                            #state/admin division clipping (offline, on QGIS) of the cropland masks bellow. Mostly used\n",
    "                                                                                            #when testing with geemap.\n",
    "\n",
    "testArea =  ee.FeatureCollection(\"projects/seamproj01/assets/test_area_v2\") #A small block in the Gezira state east of the Blue Nile, a subset of geziraCropland\n",
    "\n",
    "khartoumCropland = ee.FeatureCollection(\"projects/seamproj01/assets/khartoum_cropmask_v4_1\")    #From the Copernicus Moderate Dynamic Land Cover dataset. Extracted cropland pixels, then clipped\n",
    "                                                                                                #to Khartoum state. Polygons less than 0.3km2 in area are removed. Holes smaller than 0.5km2 are filled.\n",
    "                                                                                                #Subdivided using level 2 OCHA admin subdivions (with Karrari and Um Bada merged into one)\n",
    "geziraCropland = ee.FeatureCollection(\"projects/seamproj01/assets/gezira_cropmask_v4\")  #Also based on Copernicus MDLC, cliped first with GlobCover dataset (via FAO LCLU). Then\n",
    "                                                                                        #Seperated based on position relative to Blue Nile (east or west)\n",
    "\n",
    "testAreaSamples = ee.FeatureCollection(\"projects/seamproj01/assets/test_samples\")   #50 samples covering testArea, with a string attribute NAME matching testArea's NAME attrib,\n",
    "                                                                                    #TODO implement this: and an int attrib ISFALLOW with 1 for fallow, 0 for cultivated land. ISFALLOW is manually labeled, used as calibration data.\n",
    "                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is especially usefull for sentinel data. To try and improve performance a bit, we'll limit the collection to only target months, using ee.Filter.calendarRange(start, end, field)\n",
    "#problem is, targetMonths may no be in order (consider inter-annual years), so we can't just take first and last entry. can't take max or min either else it would defeat purpose (min/max\n",
    "#of [11, 12, 1, 2] would result in twelve months).\n",
    "def FilterCollectionForPeriod(  col : ee.ImageCollection,\n",
    "                                startDate : str,\n",
    "                                endDate : str,\n",
    "                                targetMonths : list) -> ee.ImageCollection:\n",
    "    periodStart = 0\n",
    "    periodEnd = 0\n",
    "    periods = []\n",
    "    for i in range (1, len(targetMonths)):\n",
    "        if (targetMonths[i] > targetMonths[i - 1]):\n",
    "            periodEnd = i\n",
    "        else:\n",
    "            periods.append([targetMonths[periodStart], targetMonths[periodEnd]])\n",
    "            periodStart = periodEnd = i\n",
    "\n",
    "    periods.append([targetMonths[periodStart], targetMonths[periodEnd]])\n",
    "\n",
    "    monthsFilter = ee.Filter.calendarRange(periods[0][0], periods[0][1], \"month\")\n",
    "    for i in range (1, len(periods)):\n",
    "        monthsFilter = ee.Filter.Or(monthsFilter, ee.Filter.calendarRange(periods[i][0], periods[i][1], \"month\"))\n",
    "\n",
    "    return col.filterDate(startDate, endDate).filter(monthsFilter)\n",
    "\n",
    "#Clipping image with high vertex-count polygons can take a LOT of time. So, we clip our rasters to the bounding box of these polygons, and suffer processing the extra\n",
    "#pixels. From quick testing, this is still much faster than clipping to exact geometry. Computing NDVI TS for khartoum (v3) dataset (2019-2023 winter seasons) took only\n",
    "#2 hours with the new clipping method. With the original, exact clipping, it wasn't finished even after 17hrs (canceled it at that point)\n",
    "#Note that this doesn't affect the clipping optimisation in the spatial anomaly analysis component, neither the reduceRegion(s) used in it\n",
    "def ClipCollectionToCollection(imageCol : ee.ImageCollection, featureCol : ee.FeatureCollection):\n",
    "    clipGeometry = featureCol.map(lambda feature : ee.Feature(feature.geometry().bounds())).geometry()\n",
    "    return imageCol.map(lambda image : image.clip(clipGeometry).copyProperties(image, image.propertyNames()))\n",
    "\n",
    "def ProcessMODISCollection( col : ee.ImageCollection,\n",
    "                            roi : ee.FeatureCollection,\n",
    "                            startDate : str,\n",
    "                            endDate : str,\n",
    "                            targetMonths : list) -> ee.ImageCollection:\n",
    "    \n",
    "    #mappable functions (leaving them scoped inside the MODIS function because similarily named ones with different implementation exist for Sentinel as well)\n",
    "    def MaskPoortQualityPixels(img : ee.Image) -> ee.Image:\n",
    "        qaBand = img.select(\"State\")\n",
    "        #TODO add snow/ice masking\n",
    "        mask = qaBand.bitwiseAnd(3).eq(0) #pixel is clear from cloud (bits 0 and 1)\n",
    "        mask = mask.And(qaBand.bitwiseAnd(4).eq(0)) #not cloud shadow (bit 2)\n",
    "        mask = mask.And(qaBand.bitwiseAnd(768).eq(0)) #no cirrus (bits 8 and 9)\n",
    "        return img.updateMask(mask)\n",
    "    \n",
    "    output = FilterCollectionForPeriod(col, startDate, endDate, targetMonths)\n",
    "    output = output.filterBounds(roi)\n",
    "    #output = output.map(lambda image : image.clip(roi).copyProperties(image, image.propertyNames()))\n",
    "    output = ClipCollectionToCollection(output, roi)\n",
    "    output = output.map(MaskPoortQualityPixels)\n",
    "    output = output.map(lambda image : image.normalizedDifference([\"sur_refl_b02\", \"sur_refl_b01\"]).rename(\"NDVI\").copyProperties(image, image.propertyNames()))\n",
    "    return output\n",
    "\n",
    "\n",
    "def ProcessSentinelCollection(  col : ee.ImageCollection,\n",
    "                                roi : ee.FeatureCollection,\n",
    "                                startDate : str,\n",
    "                                endDate : str,\n",
    "                                targetMonths : list) -> ee.ImageCollection:\n",
    "    \n",
    "    def MaskPoortQualityPixels(img : ee.Image) -> ee.Image:\n",
    "        qaBand = img.select(\"SCL\")\n",
    "        #Unlike MODIS, the quality band used here, \"SCL,\" contains a single int meant to be interpreted as a single int.\n",
    "        #https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/scene-classification/\n",
    "        \n",
    "        mask = qaBand.eq(3) #cloud shadows\n",
    "        mask = mask.And(qaBand.eq(6)) #water\n",
    "        mask = mask.And(qaBand.eq(8)) #medium probability clouds\n",
    "        mask = mask.And(qaBand.eq(9)) #high probability clouds\n",
    "        mask = mask.And(qaBand.eq(10)) #thin cirrus\n",
    "        mask = mask.And(qaBand.eq(11)) #snow/ice\n",
    "\n",
    "        mask = mask.neq(1) #flip so it masks out the above\n",
    "        \n",
    "        return img.updateMask(mask)\n",
    "    \n",
    "    #filter then process the output collection\n",
    "    output = FilterCollectionForPeriod(col, startDate, endDate, targetMonths)\n",
    "    output = output.filterBounds(roi)\n",
    "    output = output.select(\"B4\", \"B8\", \"SCL\") #grasping at straws trying to make this thing run faster... TODO experiment to see if this actually has an effect\n",
    "    #output = output.map(lambda image : image.clip(roi).copyProperties(image, image.propertyNames()))\n",
    "    output = ClipCollectionToCollection(output, roi)\n",
    "    output = output.map(MaskPoortQualityPixels)\n",
    "    output = output.map(lambda image : image.normalizedDifference([\"B8\", \"B4\"]).rename(\"NDVI\").copyProperties(image, image.propertyNames()))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##roi is a feature collection containing target polygons for the region of analysis\n",
    "##projectName is a string with which the name of the output raster will be prefixed\n",
    "\n",
    "roi = testArea\n",
    "projectName = \"TestProj\" \n",
    "\n",
    "# roi = geziraCropland\n",
    "# projectName = \"Gezira\" \n",
    "\n",
    "# roi = khartoumCropland\n",
    "# projectName = \"Khartoum\"\n",
    "\n",
    "#This it the name of the property (or \"attribute\", in GIS-speak) that contains the identifier for the subdivision of the roi used as climate divisions for spatial anomaly\n",
    "#analysis, and also used in splitting rasters of the output.\n",
    "subdivisionPropertyName = \"NAME\"\n",
    "\n",
    "#spatial resolution of the output file(s), in meters\n",
    "targetOutputScale = 10\n",
    "\n",
    "#This is the value for the z-score bellow which a pixel is considered fallow. Made a vairable here for caliberation purposes.\n",
    "#temporalZScoreThresholdMax = -3 #Original value used by Wallace et al.\n",
    "#temporalZScoreThresholdRange = -3 #Original value used by Wallace et al.\n",
    "temporalZScoreThresholdMax = -1.25\n",
    "temporalZScoreThresholdRange = -1.0\n",
    "\n",
    "#For spatial anomaly analysis, the max of a climate division for a given season is multiplied by this value.\n",
    "#spatialMedianMultiplierMax = 0.8 #Original value used by Wallace et al.\n",
    "#spatialMedianMultiplierMax = 0.8 #Original value used by Wallace et al.\n",
    "spatialMedianMultiplierMax = 1.0\n",
    "spatialMedianMultiplierRange = 1.0\n",
    "\n",
    "#time-series limits. All inclusive.\n",
    "yearStart = 2019\n",
    "monthStart = 1\n",
    "yearEnd = 2024\n",
    "monthEnd = 2\n",
    "\n",
    "# yearStart = 2021\n",
    "# monthStart = 7\n",
    "# yearEnd = 2022\n",
    "# monthEnd = 2\n",
    "\n",
    "#targetMonths are the months comprising the season for analysis.\n",
    "#WARNING! MUST BE 4 Values! Otherwise, the Temporal Anomaly Analysis component must be adjusted\n",
    "#WARNING! ORDER OF MONTHS MUST BE CHRONOLOGICAL! If the season is inter-annual, start with the months in the first year, then the second year\n",
    "#e.g. if the season starts on November, the list would be [11, 12, 1, 2]\n",
    "targetMonths = [7, 8, 9, 10] #\"Summer\" season in Sudan (technically Autumn). This covers the growth periods of crops such as sorghum.\n",
    "#targetMonths = [11, 12, 1, 2] #\"Winter\" season in Sudan. This covers growth periods of crops such as wheat\n",
    "\n",
    "dateStart = f\"{yearStart}-{monthStart}-1\"\n",
    "dateEnd = f\"{yearEnd}-{monthEnd + 1}-1\" if monthEnd < 12 else  f\"{yearEnd + 1}-1-1\"\n",
    "\n",
    "#Process and set ndviTS to the (processed) dataset you are using.\n",
    "modis = ee.ImageCollection(\"MODIS/061/MOD09Q1\")\n",
    "modis = ProcessMODISCollection(modis, roi, dateStart, dateEnd, targetMonths)\n",
    "ndviTS = modis\n",
    "\n",
    "# sentinel2SR = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "# sentinel2SR = ProcessSentinelCollection(sentinel2SR, roi, dateStart, dateEnd, targetMonths)\n",
    "# #TODO the Sentinel-2 L2A data used here miss some dates prior to dec 2018 for Gezira region. This is specific to GEE's version of 2A. Actual 2A on Copernicus Dataspace do cover this period.\n",
    "# #Note that GEE's L1C (the TOA version) does cover this period as well. So consider implementing a TOA-to-SR algo to augment the 2A data where it's lacking.\n",
    "# #Also note: feeding this algorithm months (within range dateStart to dateEnd) without rasters will throw exceptions.\n",
    "# ndviTS = sentinel2SR\n",
    "\n",
    "#Note: ndviTS is only used in computation of the max/range timeseries, but it's not considered in some reduceRegions and exports bellow, which require the scale of the image as argument.\n",
    "#TODO adjust the reduceRegions and Exports bellow to dynamically use the scale based on that of the selected dataset\n",
    "\n",
    "#Auto Calibration settings\n",
    "#if autoCalibrateParams is true, the model will be calibrated using calibrationDataset.\n",
    "#calibrationAttribName is the attribute column name that contains integer marking whether land is fallow or not (0 = not fallow, 1 = fallow)\n",
    "#calibrationYear is the year which the values in ISFALLOW represent\n",
    "autoCalibrateParams : bool = True\n",
    "calibrationDataset = testAreaSamples\n",
    "calibrationAttribName = \"ISFALLOW\"\n",
    "calibrationYear = 2019\n",
    "\n",
    "# alpha = 1.0 #the base \"step length\" of coordinate descent (or ascent)\n",
    "# #note: calibration is considered complete once any othe two conditions above is reached.\n",
    "# minIterations = 2 #minimum iterations to process before testing whether the break the calibration.\n",
    "# maxIterations = 100 #max number of optimisation iterations before caliberation is stopped.\n",
    "# maxInnerIterations = 10 #Put simply, the max number of subdivs of alpha to be tested for each coordiante in each [outer] iteration.\n",
    "# minChangeThreshold = 0.01 #minimum percentage of change in the objective/cost function (the error) between caliberation iterations before stopping the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Checking that enough data are available for sentinel-2 L2A for the selected roi/dates.\n",
    "# #note: this check does not use the processed data. It tests the original dataset after filtering for roi and date, to speed the process up as ProcessSentinelCollection() can\n",
    "# #take a significant of time, depending on roi.\n",
    "# periodStart = 0\n",
    "# periodEnd = 0\n",
    "# periods = []\n",
    "# for i in range (1, len(targetMonths)):\n",
    "#     if (targetMonths[i] > targetMonths[i - 1]):\n",
    "#         periodEnd = i\n",
    "#     else:\n",
    "#         periods.append([targetMonths[periodStart], targetMonths[periodEnd]])\n",
    "#         periodStart = periodEnd = i\n",
    "\n",
    "# periods.append([targetMonths[periodStart], targetMonths[periodEnd]])\n",
    "\n",
    "# monthsFilter = ee.Filter.calendarRange(periods[0][0], periods[0][1], \"month\")\n",
    "# for i in range (1, len(periods)):\n",
    "#     monthsFilter = ee.Filter.Or(monthsFilter, ee.Filter.calendarRange(periods[i][0], periods[i][1], \"month\"))\n",
    "    \n",
    "# for year in range(yearStart, yearEnd + 1):\n",
    "#     for month in targetMonths:\n",
    "#         subColStart = f\"{year}-{month}-1\"\n",
    "#         subColEnd = f\"{year}-{month + 1}-1\" if month < 12 else f\"{year + 1}-1-1\"\n",
    "#         ndviRastersForMonth = ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\").filterBounds(roi.geometry()).filterDate(subColStart, subColEnd).size().getInfo()\n",
    "\n",
    "#         print (f\"{year}-{month} : available scenes = {ndviRastersForMonth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this block, we generte the timeseries (monthly max NDVI and NDVI range) and the statistics for the \"pure crop\" signal.\n",
    "#Outputs of this block are two ImageCollections: \"timeseries,\" and \"pureCropNDVI\"\n",
    "#Note: \"year\" here is used to refer to the year of the start of the season, no the calendar year of the month. This is important for inter-annual seasons (e.g. Nov through\n",
    "#Feb). \n",
    "    #timseries contains images for each season.\n",
    "        #Each Image has number of bands equal to twice the number of targetMonths (2x4 = 8).\n",
    "        #Each Image has a property \"year\" for the season's year.\n",
    "        #Each band is named \"month_x_max\" or \"month_x_range\", where x is the month's number; \"max\" and \"range\" denote whether it encodes the maximum monthly ndvi or ndvi monthly range.\n",
    "    #pureCropNDVI contains images for each month in the targetMonths (total = 4)\n",
    "        #each image has 4 bands: \"month_x_max_mean\" or \"month_x_max_stdDev\" (and similarily for range).\n",
    "        #each image has a property \"month\" with month's number\n",
    "\n",
    "timeSeries = ee.List([])\n",
    "\n",
    "lastCompleteSeason = yearStart\n",
    "\n",
    "for year in range(yearStart, yearEnd + 1):\n",
    "    \n",
    "    yearTS = ee.List([])\n",
    "    isCompleteSeason = True\n",
    "    \n",
    "    lastMonth = 0\n",
    "    calendarYear = year\n",
    "    lastCompleteSeason = year\n",
    "\n",
    "    for month in targetMonths:\n",
    "        if (month < lastMonth):\n",
    "            calendarYear += 1\n",
    "        lastMonth = month\n",
    "        \n",
    "        if ((calendarYear * 100) + month > (yearEnd * 100) + monthEnd):\n",
    "            isCompleteSeason = False\n",
    "            break\n",
    "        \n",
    "        \n",
    "        subPeriodStart = f\"{calendarYear}-{month}-1\"\n",
    "        subPeriodEnd = f\"{calendarYear}-{month + 1}-1\" if month < 12 else  f\"{calendarYear + 1}-1-1\"\n",
    "        subCol = ndviTS.filterDate(subPeriodStart, subPeriodEnd)\n",
    "        \n",
    "        minMaxNDVI = subCol.reduce(ee.Reducer.minMax())\n",
    "\n",
    "        monthMax = minMaxNDVI.select(\"NDVI_max\").rename(\"max\")\n",
    "        monthRange = minMaxNDVI.select(\"NDVI_max\").subtract(minMaxNDVI.select(\"NDVI_min\")).rename(\"range\")\n",
    "        yearTS = yearTS.add(ee.Image([monthMax, monthRange]).set({\"system:index\" : f\"month_{month}\"}))\n",
    "    \n",
    "    if(not isCompleteSeason):\n",
    "        lastCompleteSeason += -1\n",
    "        break\n",
    "    \n",
    "    yearTS = ee.ImageCollection(yearTS).toBands().set({\"year\" : year, \"system:index\" : ee.String(\"year_\").cat(str(year))})\n",
    "    timeSeries = timeSeries.add(yearTS)\n",
    "\n",
    "timeSeries = ee.ImageCollection(timeSeries)\n",
    "\n",
    "##uncomment this part to export the ndviTS. Not very recommended for Sentinel 2 data for large areas (produces rasters between 500~900MB for Gezira dataset)...\n",
    "##to reduce output size, the data is scaled by 100 the rounded off, and stored as an unsigned, 8bit int which range 0 to 255, but because ndvi ts ranges from 0 to 1 (zero because we masked out water), the\n",
    "##resulting raster would range from 0 to 100. Also note the reduced precision this introduces (shouldn't matter much anyway)\n",
    "##TODO adjust code so bands would have name of year.\n",
    "##TODO seperate output images for this the same as you do fallowTS bellow.\n",
    "##TODO export max and range timeseries seperately\n",
    "# task = ee.batch.Export.image.toDrive(\n",
    "#     #image = timeSeries.select([f\"month_{targetMonths[0]}_max\", f\"month_{targetMonths[1]}_max\", f\"month_{targetMonths[2]}_max\", f\"month_{targetMonths[3]}_max\"]).toBands().clip(roi.geometry()).multiply(ee.Image(ee.Number(100))).toUint8(),\n",
    "#     #description = f\"{projectName}_maxNDVI_TS_{yearStart}-{yearEnd}_season_{targetMonths[0]}-{targetMonths[1]}-{targetMonths[2]}-{targetMonths[3]}\",\n",
    "#     image = timeSeries.select([f\"month_{targetMonths[0]}_range\", f\"month_{targetMonths[1]}_range\", f\"month_{targetMonths[2]}_range\", f\"month_{targetMonths[3]}_range\"]).toBands().clip(roi.geometry()).multiply(ee.Image(ee.Number(100))).toUint8(),\n",
    "#     description = f\"{projectName}_rangeNDVI_TS_{yearStart}-{yearEnd}_season_{targetMonths[0]}-{targetMonths[1]}-{targetMonths[2]}-{targetMonths[3]}\",\n",
    "#     #folder='ee_export',\n",
    "#     region = roi.geometry(),\n",
    "#     scale = targetOutputScale,\n",
    "#     crs = 'EPSG:4326',\n",
    "#     maxPixels = 500000000,\n",
    "#     fileFormat = 'GeoTIFF',\n",
    "#     formatOptions = {\n",
    "#         'noData': -9999\n",
    "# })\n",
    "# task.start()\n",
    "\n",
    "\n",
    "pureCropNDVI = ee.List([])\n",
    "\n",
    "for month in targetMonths:\n",
    "    prefix = f\"month_{month}_\"\n",
    "    thisMonthTS = timeSeries.select([prefix + \"max\", prefix + \"range\"])\n",
    "\n",
    "    monthMedian = thisMonthTS.reduce(ee.Reducer.median()).rename([prefix + \"max\", prefix + \"range\"]).set({\"month\" : month})\n",
    "    \n",
    "    meanStdReducer = ee.Reducer.mean().combine(ee.Reducer.stdDev(), sharedInputs = True)\n",
    "\n",
    "    monthPureCropNDVI = thisMonthTS.map(lambda img : img.updateMask(img.gte(monthMedian)))\n",
    "    monthPureCropNDVI = monthPureCropNDVI.reduce(meanStdReducer).set(\"month\", month)\n",
    "\n",
    "    pureCropNDVI = pureCropNDVI.add(monthPureCropNDVI)\n",
    "\n",
    "pureCropNDVI = ee.ImageCollection(pureCropNDVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block computes the temporal anomalies (z-scores) for each season. The output is an ImageCollection called temporalAnomalies, containing Images representing each season.\n",
    "    #Each Image has number of bands equal to twice the number of targetMonths (2x4 = 8).\n",
    "    #Each Image has a property \"year\" for the season's year.\n",
    "    #Each band is named \"month_x_max\" or \"month_x_range\", respectively for the z-scores for max NDVI and NDVI range, for each target month.\n",
    "\n",
    "def ComputeTemporalAnomalies(image : ee.Image) -> ee.Image:\n",
    "    seasonAnomalies = ee.List([])\n",
    "\n",
    "    for month in targetMonths:\n",
    "        prefix = f\"month_{month}_\"\n",
    "        pureCropSignal = pureCropNDVI.filter(ee.Filter.eq(\"month\", month)).first()\n",
    "        \n",
    "        taMax = image.select(prefix + \"max\").subtract(pureCropSignal.select(prefix + \"max_mean\")).divide(pureCropSignal.select(prefix + \"max_stdDev\")).rename(\"max\")\n",
    "        taRange = image.select(prefix + \"range\").subtract(pureCropSignal.select(prefix + \"range_mean\")).divide(pureCropSignal.select(prefix + \"range_stdDev\")).rename(\"range\")\n",
    "\n",
    "        ta = ee.Image([taMax, taRange]).set({\"system:index\" : f\"month_{month}\"})\n",
    "        seasonAnomalies = seasonAnomalies.add(ta)\n",
    "    \n",
    "    return ee.ImageCollection(seasonAnomalies).toBands().set({\"year\" : image.get(\"year\")})\n",
    "    \n",
    "\n",
    "\n",
    "temporalAnomalies = timeSeries.map(ComputeTemporalAnomalies)\n",
    "\n",
    "##uncomment this part to export the anomaly series.\n",
    "##similarily to ndvi timeseries export, the data is scaled by 100 the rounded off, and stored as a 16bit int with range -32,768 to 32,767\n",
    "##since z score shouldn't go far from zero (negative or positive single digits, typically), this range should be more than adequte.\n",
    "##Note: gee refuses to set image index (its name) inside map(). So the output image will be prefixed with integers starting from 0, instead of year number.\n",
    "##TODO seperate output images for this the same as you do fallowTS bellow.\n",
    "##TODO export max and range series seperately\n",
    "# task = ee.batch.Export.image.toDrive(\n",
    "#     image = temporalAnomalies.toBands().clip(roi.geometry()).multiply(ee.Image(ee.Number(100))).toInt16(),\n",
    "#     description = f\"{projectName}_temporalAnomalies_{yearStart}-{yearEnd}_season_{targetMonths[0]}-{targetMonths[1]}-{targetMonths[2]}-{targetMonths[3]}\",\n",
    "#     #folder='ee_export',\n",
    "#     region = roi.geometry(),\n",
    "#     scale = targetOutputScale, #WARNING! The zscore data isn't very compressible, even when reduced to int16. Using large scales (less than 30m) with large areas (gezira example) results in rasters 11GB in size\n",
    "#     crs = 'EPSG:4326',\n",
    "#     maxPixels = 500000000,\n",
    "#     fileFormat = 'GeoTIFF',\n",
    "#     formatOptions = {\n",
    "#         'noData': -9999\n",
    "# })\n",
    "# task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporal analysis component.\n",
    "\n",
    "#mapable function, mapped over temporalAnomalies collection\n",
    "def TemporalAnomalyAnalysis(image : ee.Image) -> ee.Image: #to be mapped over temporalAnomalies collection\n",
    "    isFallow_1 = image.select(f\"month_{targetMonths[0]}_max\").lt(temporalZScoreThresholdMax).And(image.select(f\"month_{targetMonths[1]}_max\").lt(temporalZScoreThresholdMax)).And(image.select(f\"month_{targetMonths[2]}_max\").lt(temporalZScoreThresholdMax))\n",
    "    isFallow_1 = isFallow_1.Or(image.select(f\"month_{targetMonths[1]}_max\").lt(temporalZScoreThresholdMax).And(image.select(f\"month_{targetMonths[2]}_max\").lt(temporalZScoreThresholdMax)).And(image.select(f\"month_{targetMonths[3]}_max\").lt(temporalZScoreThresholdMax)))\n",
    "    isFallow_1 = isFallow_1.rename(\"max\")\n",
    "\n",
    "    isFallow_2 = image.select(f\"month_{targetMonths[0]}_range\").lt(temporalZScoreThresholdRange).And(image.select(f\"month_{targetMonths[1]}_range\").lt(temporalZScoreThresholdRange)).And(image.select(f\"month_{targetMonths[2]}_range\").lt(temporalZScoreThresholdRange))\n",
    "    isFallow_2 = isFallow_2.Or(image.select(f\"month_{targetMonths[1]}_range\").lt(temporalZScoreThresholdRange).And(image.select(f\"month_{targetMonths[2]}_range\").lt(temporalZScoreThresholdRange)).And(image.select(f\"month_{targetMonths[3]}_range\").lt(temporalZScoreThresholdRange)))\n",
    "    isFallow_2 = isFallow_2.rename(\"range\")\n",
    "\n",
    "    return ee.Image([isFallow_1, isFallow_2]).set({\"year\" : image.get(\"year\")})\n",
    "\n",
    "#isFallow_TA the two questions for the temporal anomalies\n",
    "isFallow_TA = temporalAnomalies.map(TemporalAnomalyAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial analysis component.\n",
    "zones = roi.toList(roi.size())\n",
    "zonesSize = zones.size().getInfo()\n",
    "\n",
    "print(f\"Processing spatial anomalies for {zonesSize} zone(s)\")\n",
    "\n",
    "#cache clipped rasters (with constant value of zero) to avoid clipping in the loops bellow \n",
    "#rationale for this is that SpatialAnomalyAnalysis() would call clipping for n * m * k, where n = number of target months, m = number of subfeatures, and k = number\n",
    "#of years. Whereas clipping it here does so only m times. Replacing the internal clipping with addition ops.\n",
    "baseClippedRasters = ee.List([])\n",
    "for i in  range(0, zonesSize):\n",
    "    baseClippedRasters = baseClippedRasters.add(ee.Image(0.0).clip(ee.Feature(zones.get(i)).geometry()).toFloat())\n",
    "\n",
    "#mapable function, mapped over timeseries collection to generate input for spatial anomal analysis\n",
    "def SpatialStatistics(image : ee.Image) -> ee.Image:\n",
    "    maxOfMax = ee.List([])\n",
    "    maxOfRange = ee.List([])\n",
    "    \n",
    "    spatialMedianMax = ee.List([])\n",
    "    spatialMedianRange = ee.List([])\n",
    "    \n",
    "    for month in targetMonths:\n",
    "        name = f\"month_{month}\"\n",
    "        _maxOfMax = image.select(name + \"_max\").rename(\"max\")\n",
    "        _maxOfRange = image.select(name + \"_range\").rename(\"range\")\n",
    "\n",
    "        monthSpatialMedianMax = ee.List([])\n",
    "        monthSpatialMedianRange = ee.List([])\n",
    "        \n",
    "        maxOfMax = maxOfMax.add(_maxOfMax)\n",
    "        maxOfRange = maxOfRange.add(_maxOfRange)\n",
    "\n",
    "        for i in  range(0, zonesSize):\n",
    "            targetZone = ee.Feature(zones.get(i)).geometry()\n",
    "            zoneMaxMedian =  _maxOfMax.reduceRegion(   reducer = ee.Reducer.median(),\n",
    "                                                        geometry = targetZone,\n",
    "                                                        tileScale = 4,\n",
    "                                                        scale = 250, #TODO this was increased in the original, single zone implementation. Test setting it back.\n",
    "                                                        maxPixels = 5000000, #TODO same as above (reduced from default 10mil)\n",
    "                                                        bestEffort = True,\n",
    "                                                        crs='EPSG:4326',\n",
    "                                                        ).getNumber(\"max\")\n",
    "            \n",
    "            zoneRangeMedian =  _maxOfRange.reduceRegion(    reducer = ee.Reducer.median(),\n",
    "                                                            geometry = targetZone,\n",
    "                                                            tileScale = 4,\n",
    "                                                            scale = 250,\n",
    "                                                            maxPixels = 5000000,\n",
    "                                                            bestEffort = True,\n",
    "                                                            crs='EPSG:4326',\n",
    "                                                            ).getNumber(\"range\")\n",
    "            \n",
    "            zoneBaseRaster = ee.Image(baseClippedRasters.get(i))\n",
    "\n",
    "            zoneMaxMedian = zoneBaseRaster.add(ee.Image(zoneMaxMedian)).toFloat()\n",
    "            zoneRangeMedian = zoneBaseRaster.add(ee.Image(zoneRangeMedian)).toFloat()\n",
    "\n",
    "            monthSpatialMedianMax = monthSpatialMedianMax.add(zoneMaxMedian)\n",
    "            monthSpatialMedianRange = monthSpatialMedianRange.add(zoneRangeMedian)\n",
    "        \n",
    "        monthSpatialMedianMax = ee.ImageCollection(monthSpatialMedianMax).mosaic()\n",
    "        monthSpatialMedianRange = ee.ImageCollection(monthSpatialMedianRange).mosaic()\n",
    "\n",
    "        spatialMedianMax = spatialMedianMax.add(monthSpatialMedianMax)\n",
    "        spatialMedianRange = spatialMedianRange.add(monthSpatialMedianRange)\n",
    "\n",
    "    maxOfMax = ee.ImageCollection(maxOfMax).reduce(ee.Reducer.max()).rename(\"maxOfMax\")\n",
    "    maxOfRange = ee.ImageCollection(maxOfRange).reduce(ee.Reducer.max()).rename(\"maxOfRange\")\n",
    "\n",
    "    spatialMedianMax = ee.ImageCollection(spatialMedianMax).reduce(ee.Reducer.max(), parallelScale = 4).rename(\"medianOfMax\")\n",
    "    spatialMedianRange = ee.ImageCollection(spatialMedianRange).reduce(ee.Reducer.max(), parallelScale = 4).rename(\"medianOfRange\")\n",
    "    \n",
    "    return ee.Image([maxOfMax, maxOfRange, spatialMedianMax, spatialMedianRange]).set({\"year\" : image.get(\"year\")})\n",
    "\n",
    "#mapable function, mapped over spatial statistics to generate the isFallow rasters based on spatial anomalies\n",
    "def SpatialAnomalyAnalysis(image : ee.Image) -> ee.Image:\n",
    "    maxOfMax = image.select(\"maxOfMax\")\n",
    "    maxOfRange = image.select(\"maxOfRange\")\n",
    "    spatialMedianMax = image.select(\"medianOfMax\")\n",
    "    spatialMedianRange = image.select(\"medianOfRange\")\n",
    "\n",
    "    isFallow_3 = maxOfMax.lt(spatialMedianMax.multiply(ee.Number(spatialMedianMultiplierMax))).rename(\"max\")\n",
    "    isFallow_4 = maxOfRange.lt(spatialMedianRange.multiply(ee.Number(spatialMedianMultiplierRange))).rename(\"range\")\n",
    "\n",
    "    return ee.Image([isFallow_3, isFallow_4]).set({\"year\" : image.get(\"year\")})\n",
    "\n",
    "\n",
    "#isFallow_SA the two questions for the spatial anomalies\n",
    "spatialStats = timeSeries.map(SpatialStatistics)\n",
    "isFallow_SA = spatialStats.map(SpatialAnomalyAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final analysis.\n",
    "#For a pixel to qualify as fallow, it has to be classified as such in at least two of either the temporal or spatial checks.\n",
    "\n",
    "def ComputeFallowTS(isFallow_TA, isFallow_SA):\n",
    "    isFallowComponents = ee.List([])\n",
    "    for year in range (yearStart, yearEnd + 1):\n",
    "        if ((year * 100) + targetMonths[0] > (yearEnd * 100) + monthEnd):\n",
    "                break\n",
    "                \n",
    "        yearComponents = ee.List([]).add(isFallow_TA.filter(ee.Filter.eq(\"year\", year)).first().set({\"system:index\" : f\"{year}_TA\"}))\n",
    "        yearComponents = yearComponents.add(isFallow_SA.filter(ee.Filter.eq(\"year\", year)).first().set({\"system:index\" : f\"{year}_SA\"}))\n",
    "\n",
    "        yearComponents = ee.ImageCollection(yearComponents).toBands().set({\"year\" : str(year)})\n",
    "        isFallowComponents = isFallowComponents.add(yearComponents)\n",
    "\n",
    "    isFallowComponents = ee.ImageCollection(isFallowComponents)\n",
    "    \n",
    "    return isFallowComponents.map(lambda img : img.reduce(ee.Reducer.sum()).gte(ee.Number(2)).rename(ee.String(img.get(\"year\")))).toBands()\n",
    "\n",
    "\n",
    "fallowTS = ComputeFallowTS(isFallow_TA, isFallow_SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cache temporatlAnomalies and spatialStats (which are expensive to compute) as an asset to be used for optimisation\n",
    "\n",
    "pathPrefix = \"projects/seamproj01/assets/\"\n",
    "\n",
    "task = ee.batch.Export.image.toAsset(temporalAnomalies.toBands().clip(roi.geometry()), \n",
    "                                     \"temporalAnomalies\",  \n",
    "                                     pathPrefix + \"tempAn\", \n",
    "                                     scale = 10, \n",
    "                                     maxPixels= 3e8)\n",
    "#task.start()\n",
    "\n",
    "task = ee.batch.Export.image.toAsset(spatialStats.toBands().clip(roi.geometry()), \n",
    "                                     \"spatialStats\",  \n",
    "                                     pathPrefix + \"spStat\", \n",
    "                                     scale = 10, \n",
    "                                     maxPixels= 3e8)\n",
    "\n",
    "# task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreate temporaAnomalies and spatialStats from cached rasters\n",
    "#Reminder: for temporalAnomalies:\n",
    "    #Each Image has number of bands equal to twice the number of targetMonths (2x4 = 8).\n",
    "    #Each Image has a property \"year\" for the season's year.\n",
    "    #Each band is named \"month_x_max\" or \"month_x_range\", respectively for the z-scores for max NDVI and NDVI range, for each target month.\n",
    "#reminder for spatialStats:\n",
    "    #each image has property \"year\"\n",
    "    #each image has four bands: maxOfMax, maxOfRange, medianOfMax, and medianOfRange\n",
    "\n",
    "#TODO skip this block if not autocaliberating\n",
    "\n",
    "tempAnImg = ee.Image(pathPrefix + \"tempAn\")\n",
    "spStatImg = ee.Image(pathPrefix + \"spStat\")\n",
    "\n",
    "#To make life a little bit easier, clip the rasters above to a small area around the sampling points, since we don't need the whole region for calibration,\n",
    "#which is what we are doing if we are in this block\n",
    "\n",
    "clipper = testAreaSamples.map(lambda point : point.buffer(250)) #ideally, we would clip only the pixel, but since we don't know where it is exactly (and rasters vary in res)...\n",
    "#buffer on a point returns a circle, let's convert it to a rectangle. Not necessary, but I like rects better for these kinda things :) Using the circles bounds simplifis this.\n",
    "clipper = roi.map(lambda circle : ee.Geometry.Rectangle(ee.Array.cat(circle.geometry().bounds().coordinates(),1).slice(0, 0, 3, 2).reshape([-1]).toList()))\n",
    "\n",
    "tempAnImg = tempAnImg.clip(clipper.geometry())\n",
    "spStatImg = spStatImg.clip(clipper.geometry())\n",
    "\n",
    "\n",
    "temporalAnomalies = ee.List([])\n",
    "spatialStats = ee.List([])\n",
    "\n",
    "spStatsNames = [\"maxOfMax\", \"maxOfRange\", \"medianOfMax\", \"medianOfRange\"]\n",
    "taBandNames = [] #the process bellow breaks the band naming (prefexes an integer), generate this list for easier renaming bellow.\n",
    "for m in targetMonths:\n",
    "    taBandNames.append(f\"month_{m}_max\")\n",
    "    taBandNames.append(f\"month_{m}_range\")\n",
    "\n",
    "yearsList = [int(i[5:9]) for i in tempAnImg.bandNames().getInfo()]  #workaround for an issue introduced by inter-annual seasons.\n",
    "\n",
    "for year in range(yearStart, yearEnd + 1):\n",
    "    if year not in yearsList:  #workaround for an issue introduced by inter-annual seasons.\n",
    "        continue\n",
    "\n",
    "    yearImgTA = ee.List([])\n",
    "    #temporal anomalies are by month, so we loop over targetMonths\n",
    "    for month in targetMonths:\n",
    "        bandNameMax = f\"year_{year}_month_{month}_max\"\n",
    "        bandNameRange = f\"year_{year}_month_{month}_range\"\n",
    "        \n",
    "        yearImgTA = yearImgTA.add(tempAnImg.select(bandNameMax).rename([f\"month_{month}_max\"]))\n",
    "        yearImgTA = yearImgTA.add(tempAnImg.select(bandNameRange).rename([f\"month_{month}_range\"]))\n",
    "\n",
    "    #spatialStats are for an entire year, not by month.\n",
    "    yearImgSS = ee.ImageCollection([spStatImg.select(f\"year_{year}_{statName}\") for statName in spStatsNames]).toBands().rename(spStatsNames).set({\"year\" : year})\n",
    "\n",
    "    temporalAnomalies = temporalAnomalies.add(ee.ImageCollection(yearImgTA).toBands().set({\"year\" : year}).rename(taBandNames))\n",
    "    spatialStats = spatialStats.add(yearImgSS)\n",
    "\n",
    "temporalAnomalies = ee.ImageCollection(temporalAnomalies)\n",
    "spatialStats = ee.ImageCollection(spatialStats)\n",
    "\n",
    "# #test\n",
    "print (\"for tempAn\")\n",
    "print (temporalAnomalies.first().bandNames().getInfo())\n",
    "print (temporalAnomalies.aggregate_array(\"year\").getInfo())\n",
    "# print (\"for spStat\")\n",
    "# print (spatialStats.first().bandNames().getInfo())\n",
    "# print (spatialStats.aggregate_array(\"year\").getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP\n",
    "#Autocaliberation using [TODO]\n",
    "\n",
    "#TODO Check that autoCalibrate is set to True, if not, skip this block.\n",
    "\n",
    "from random import seed as Seed, random as Random, randrange as RandIntRange\n",
    "\n",
    "#Should usually be called before RecomputeFallowTS(), else the latter will use old parameters.\n",
    "def UpdateParams(parameters):\n",
    "    global temporalZScoreThresholdMax\n",
    "    global temporalZScoreThresholdRange\n",
    "    global spatialMedianMultiplierMax\n",
    "    global spatialMedianMultiplierRange\n",
    "\n",
    "    temporalZScoreThresholdMax = parameters[0]\n",
    "    temporalZScoreThresholdRange = parameters[1]\n",
    "    spatialMedianMultiplierMax = parameters[2]\n",
    "    spatialMedianMultiplierRange = parameters[3]\n",
    "\n",
    "\n",
    "def RecomputeFallowTS():\n",
    "    # return #test\n",
    "    return ComputeFallowTS(temporalAnomalies.map(TemporalAnomalyAnalysis),\n",
    "                           spatialStats.map(SpatialAnomalyAnalysis))\n",
    "\n",
    "#assumes fallowTS is up to date\n",
    "def SampleIsFallowAtValidationPoints(fallowTS):\n",
    "    isFallowRaster = fallowTS.select(f\"..{calibrationYear}\") #output of fallowTS generation prepends an int from 0 onwards then an underscore. TODO fix\n",
    "    bandName = isFallowRaster.bandNames().get(0)\n",
    "    \n",
    "    #mappable function\n",
    "    def Sample(point):\n",
    "        value = ee.Number(isFallowRaster.sample(region = point.geometry(), scale = 10).first().get(bandName))\n",
    "        return point.set({\"estimate\" : value})\n",
    "\n",
    "    return testAreaSamples.map(Sample)\n",
    "\n",
    "#assumes fallowTS is up to date\n",
    "def ObjectiveFunction(fallowTS):\n",
    "\n",
    "    # return round(Random(),2) #test\n",
    "    data = SampleIsFallowAtValidationPoints(fallowTS)\n",
    "\n",
    "    #mappable function, to help with confusion matrix generation\n",
    "    def AddCompositeColumn(point):\n",
    "        return point.set({\"compositeScore\" : ee.Number((ee.Number(2).multiply(point.get(\"estimate\")).add(point.get(calibrationAttribName))))})\n",
    "\n",
    "    adjustedSamples = ee.Dictionary(data.map(AddCompositeColumn).aggregate_array(\"compositeScore\").reduce(ee.Reducer.frequencyHistogram()))\n",
    "    confArray = ee.Array([[adjustedSamples.get(\"3.0\", 0.0), adjustedSamples.get(\"1.0\", 0.0)], [adjustedSamples.get(\"2.0\", 0.0), adjustedSamples.get(\"0.0\", 0.0)]], ee.PixelType.float())\n",
    "    confMatrix = ee.ConfusionMatrix(confArray.long())\n",
    "    \n",
    "    return confMatrix.accuracy().getInfo() #TODO should we use Kappa?\n",
    "\n",
    "def StopOptimisation(currentIteration, currentScore, lastScore) -> bool:\n",
    "    if currentIteration < minIterations:\n",
    "        return False\n",
    "\n",
    "    if currentIteration >= maxIterations:\n",
    "        print(f\"Stopping after reaching max iterations\")\n",
    "        return True\n",
    "\n",
    "    errorMetricChange = abs((lastScore - currentScore) / lastScore)\n",
    "    if errorMetricChange <= minChangeThreshold:\n",
    "        print(f\"Stopping for stagnating improvements. Change percentage = {errorMetricChange}\")\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def RandomParams(ranges: list[list]) -> list:\n",
    "    params = []\n",
    "    for range in ranges:\n",
    "        params.append(range[0] + Random() * (range[1] - range[0]))\n",
    "    return params\n",
    "\n",
    "def RandomAgents(agents: list[list], excludeID: int, count = 3) -> list[list]:\n",
    "    picksIDs = []\n",
    "    \n",
    "    while len(picksIDs) < count:\n",
    "        i = RandIntRange(0, len(agents))\n",
    "        if i not in picksIDs and i != excludeID:\n",
    "            picksIDs.append(i)\n",
    "\n",
    "    return [agents[i] for i in picksIDs]\n",
    "\n",
    "def Clamp(value: float, range: list[float, float]) -> float:\n",
    "    return max(min(value, max(range[0], range[1])), min(range[0], range[1]))\n",
    "\n",
    "currentScore = ObjectiveFunction(RecomputeFallowTS()) #could do with existing fallowTS, but since params may have changed after its generation in the previous \n",
    "                                                #block (e.g. during test), better recompute it just to be safe.\n",
    "\n",
    "popSize = 20 #Population size. Minimum = 4 Recommended estimate is 10 * parameters. in our case, 10 * 4 = 40 #TODO move to input block, should be 10*paramCount\n",
    "crossOverProb = 0.9 #Cross Over Probability. Should be between 0.0 and 1.0. Recommended default = 0.9 #TODO move to input block\n",
    "diffWeight = 0.8 #Differential Weight. Between 0.0 and 2.0. Recommended default = 0.8 #TODO move to input block\n",
    "paramRanges = [[-0.5, -5.0], [-0.5, -5.0], [0.1, 2.0], [0.1, 2.0]] #Allowble range for each parameter.\n",
    "                                                                    #order = temporalZScoreThresholdMax, temporalZScoreThresholdRange, spatialMedianMultiplierMax,\n",
    "                                                                    #and spatialMedianMultiplierRange #TODO move to input block\n",
    "diffEvSeed = 485138463513684685 #seed for the randomizer. Ensures reproducability. Setting to None makes each run different than preceding one #TODO move to input block\n",
    "minIterations = 10 #Optimisation shall proceed no less than this number #TODO move to input block\n",
    "maxIterations = 30 #Optimisation shall break at this number regardless of results #TODO move to input block\n",
    "minChangeThreshold = 0.01 #minimum (percentage) change between iterations before stopping optimisation #TODO move to input block\n",
    "\n",
    "Seed(diffEvSeed) #TODO move this to the start of ***THIS*** block, after the related import (and after moving the variables above to their blocks)\n",
    "\n",
    "#init population\n",
    "agents = []\n",
    "scores = [] #same index as agents\n",
    "for i in range (0, popSize):\n",
    "    randAgent = RandomParams(paramRanges)\n",
    "    while randAgent in agents: #Should be a practical impossibility to happen, but still...\n",
    "        randAgent = RandomParams(paramRanges)\n",
    "    agents.append(randAgent)\n",
    "    UpdateParams(randAgent)\n",
    "    scores.append(ObjectiveFunction(RecomputeFallowTS()))\n",
    "\n",
    "\n",
    "print (f\"Agents = {len(agents)}\") #test\n",
    "for i in range (0, popSize): print(f\"{scores[i]} -- {agents[i]}\") #test\n",
    "\n",
    "bestScore = [0.0, []]\n",
    "currentScore = minChangeThreshold * 1.1\n",
    "iteration = 0\n",
    "\n",
    "while not StopOptimisation(iteration, currentScore, bestScore[0]):\n",
    "    print (f\"------------------------------\\nIteration {iteration} -- params: {bestScore[1]} -- score current: {currentScore} last: {bestScore[0]}\")\n",
    "    currentScore = bestScore[0]\n",
    "\n",
    "    for i in range (0, popSize):\n",
    "        assistVectors = RandomAgents(agents, i, 3)\n",
    "\n",
    "        testedAgent = list(agents[i])\n",
    "        rIndex = RandIntRange(0, len(paramRanges))\n",
    "        weights = RandomParams([[0.0, 1.0]] * len(paramRanges))\n",
    "        for j in range (0, len(paramRanges)):\n",
    "            if weights[j] < crossOverProb or j == rIndex:\n",
    "                testedAgent[j] = Clamp(assistVectors[0][j] + diffWeight * (assistVectors[1][j] - assistVectors[2][j]), paramRanges[j])\n",
    "\n",
    "        UpdateParams(testedAgent)\n",
    "        testedScore = ObjectiveFunction(RecomputeFallowTS())\n",
    "\n",
    "        if (testedScore > scores[i]):\n",
    "            print (f\"\\t\\tAgent {i} improved from {scores[i]} to {testedScore} - Now: {testedAgent}\")\n",
    "            agents[i] = testedAgent\n",
    "            scores[i] = testedScore\n",
    "        else:\n",
    "            print (f\"\\t\\tAgent {i} no improvement ({scores[i]})\")\n",
    "        \n",
    "        if(testedScore > bestScore[0]):\n",
    "            bestScore = [testedScore, testedAgent]\n",
    "\n",
    "    print(f\"Best scorer: {bestScore[1]} -- {bestScore[0]}\")\n",
    "    iteration += 1\n",
    "    pass\n",
    "\n",
    "\n",
    "print (f\"=================\\n Finished after {iteration} iterations\")\n",
    "print (f\"{bestScore[0]} -- {bestScore[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result export\n",
    "\n",
    "noDataValue = -9999\n",
    "\n",
    "#split raster into multiple ones based on zone, then export\n",
    "#TODO make the splitting optional\n",
    "for i in range (0, zonesSize):\n",
    "    targetZone = ee.Feature(zones.get(i))\n",
    "    exportName = f\"{projectName}_{targetZone.get(subdivisionPropertyName).getInfo()}_fallow_ts_{yearStart}-{yearEnd}_season_{targetMonths[0]}-{targetMonths[1]}-{targetMonths[2]}-{targetMonths[3]}\"\n",
    "    print (f\"{i} - exporting file: {exportName}\")\n",
    "    \n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "    image = fallowTS.clip(targetZone.geometry()),\n",
    "    description = exportName,\n",
    "    region = targetZone.geometry(),\n",
    "    scale = targetOutputScale,\n",
    "    crs = 'EPSG:4326',\n",
    "    maxPixels = 300000000,\n",
    "    fileFormat = 'GeoTIFF',\n",
    "    formatOptions = {'noData': noDataValue})\n",
    "\n",
    "    task.start()\n",
    "\n",
    "\n",
    "## This part exports the four fallow components. Mostly used for testing and checking the internal working of the aglorithm.\n",
    "# isFallowComponentsCollapsed = isFallowComponents.toBands()\n",
    "# for i in range (0, zonesSize):\n",
    "#     targetZone = ee.Feature(zones.get(i))\n",
    "#     exportName = f\"{projectName}_{targetZone.get(subdivisionPropertyName).getInfo()}_fallow_components_{yearStart}-{yearEnd}_season_{targetMonths[0]}-{targetMonths[1]}-{targetMonths[2]}-{targetMonths[3]}\"\n",
    "\n",
    "#     task = ee.batch.Export.image.toDrive(\n",
    "#     image = isFallowComponentsCollapsed.clip(targetZone.geometry()),\n",
    "#     description = exportName,\n",
    "#     #folder = 'ee_export',\n",
    "#     region = targetZone.geometry(),\n",
    "#     scale = targetOutputScale,\n",
    "#     crs = 'EPSG:4326',\n",
    "#     fileFormat = 'GeoTIFF',\n",
    "#     formatOptions = {'noData': noDataValue})\n",
    "\n",
    "#     task.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
